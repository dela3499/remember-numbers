{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import toolz as tz\n",
    "execfile(\"./utils.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some resources for the project\n",
    "\n",
    " - http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    " - http://www.nltk.org/book/ch11.html\n",
    " - https://en.wikipedia.org/wiki/Mnemonic_major_system\n",
    " - https://github.com/rhdunn/cmudict-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_mnemonic_line(line):\n",
    "    phoneme, value = line.split(\" \")\n",
    "    return (phoneme, value)\n",
    "\n",
    "mnemonic_map = tz.thread_last(\n",
    "    \"./mnemonics.txt\",\n",
    "    read_lines,\n",
    "    (map, parse_mnemonic_line),\n",
    "    dict\n",
    ")\n",
    "\n",
    "mnemonic_phonemes = mnemonic_map.keys()\n",
    "illegal_phonemes = [phoneme for phoneme, value in mnemonic_map.items() if value == \"X\"]\n",
    "legal_phonemes = [phoneme for phoneme, value in mnemonic_map.items() if value != \"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_cmu_line(line):\n",
    "    chunks = line.split()\n",
    "    word = strip_suffix(chunks[0], [\"(1)\", \"(2)\", \"(3)\", \"(4)\"])\n",
    "    drop_numbers = lambda string: \"\".join([char for char in string if char not in \"0123456789\"])\n",
    "    is_consonant = lambda phoneme: phoneme in mnemonic_phonemes\n",
    "    \n",
    "    all_phonemes = map(drop_numbers, chunks[1:]) # emphasis annotations aren't needed here\n",
    "    phonemes = filter(is_consonant, all_phonemes) # vowels aren't part of the mnemonic\n",
    "    numbers = [mnemonic_map[phoneme] for phoneme in phonemes]\n",
    "    \n",
    "    if (nvenn(phonemes, illegal_phonemes)[1] > 0) or (nvenn(phonemes, legal_phonemes)[1] < 1):\n",
    "        return [] # ignore words with illegal phonemes, or which contain no allowed phonemes\n",
    "    else: \n",
    "        return [{\"word\": word, \"phonemes\": phonemes, \"all_phonemes\": all_phonemes, \"numbers\": numbers}]\n",
    "    \n",
    "cmu = tz.thread_last(\n",
    "    './cmudict.txt',\n",
    "    read_file,\n",
    "    split_lines,\n",
    "    (filter, lambda line: not line.startswith(\";;;\")),\n",
    "    (tz.mapcat, parse_cmu_line),\n",
    "    list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_words(f): \n",
    "    return [entry for entry in cmu if f(entry['word'])]\n",
    "\n",
    "def search_numbers(f): \n",
    "    return [entry['word'] for entry in cmu if f(entry['numbers'])]\n",
    "\n",
    "def search_phonemes(f): \n",
    "    return [entry for entry in cmu if f(entry['phonemes'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def partition(n, seq):\n",
    "    if len(seq) <= n:\n",
    "        return [seq]\n",
    "    else: \n",
    "        return [seq[:n]] + partition(n, seq[n:])\n",
    "    \n",
    "def translate(numbers):\n",
    "    return tz.thread_last(\n",
    "        numbers, \n",
    "        str,\n",
    "        list,\n",
    "        (partition, 3),\n",
    "        (map, lambda query_numbers: search_numbers(lambda numbers: numbers == query_numbers)),\n",
    "        list\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it out!\n",
    "Try converting some numbers into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AUTONOMY',\n",
       "  'AUTONOMY',\n",
       "  'DENHAM',\n",
       "  'DENIM',\n",
       "  'DENOMME',\n",
       "  'DONHAM',\n",
       "  'DOWNHAM',\n",
       "  'DOWNUM',\n",
       "  'DUNHAM',\n",
       "  'DUNNAM',\n",
       "  'DYNAMO',\n",
       "  'IDEONOMY']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALARM', 'ANAMARIA', 'AHMANN']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in translate(54323432)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find good metric for results. Should be easy to remember and visualize.\n",
    " - maybe use part of speech\n",
    " - manually select your favorite matches\n",
    " - best is probably to assess how common the word is (how? using other nltk corpus?)\n",
    " \n",
    " \n",
    "If I only allow for 3-digit matches, then that 10^3 combinations to think about. So, there are around 1000 cases to handle. For each of these, it might be good to have several words to choose from so things are more interesting. Some manual work is conceivable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'n', u'n', u'n', u'n', u'n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to get parts of speech\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('HEAD')[:5]\n",
    "[x.pos() for x in wn.synsets('HEAD')[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequencies\n",
    "This could help pick the best match from a set of options. \n",
    " - http://subtlexus.lexique.org/\n",
    " - http://www.natcorp.ox.ac.uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
